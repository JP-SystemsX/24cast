{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "id": "frfor6Q_gryv",
        "outputId": "8699026f-9805-4689-d823-9d570b422a95"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def train_test_split():\n",
        "    lp_20ips_2016 = pd.read_csv(\"LoadProfile_20IPs_2016.csv\", sep=\";\", skiprows=1)\n",
        "    lp_30ips_2017 = pd.read_csv(\"LoadProfile_30IPs_2017.csv\", sep=\";\", skiprows=1)\n",
        "\n",
        "    lp_20ips_2016[\"Time stamp\"] = lp_20ips_2016[\"Time stamp\"].str.replace(r'[^0-9.: ]', '', regex=True).str.strip()\n",
        "    lp_20ips_2016[\"Time stamp\"] = pd.to_datetime(lp_20ips_2016.loc[:, \"Time stamp\"], format='%d.%m.%Y %H:%M:%S')\n",
        "\n",
        "    lp_30ips_2017[\"Time stamp\"] = lp_30ips_2017[\"Time stamp\"].str.replace(r'[^0-9.: ]', '', regex=True).str.strip()\n",
        "    lp_30ips_2017[\"Time stamp\"] = pd.to_datetime(lp_30ips_2017.loc[:, \"Time stamp\"], format='%d.%m.%Y %H:%M:%S')\n",
        "\n",
        "    train_2016_full = lp_20ips_2016.iloc[:, :-7]\n",
        "    train_2017_full = lp_30ips_2017.iloc[:, :-8]\n",
        "    test_2016_full = pd.concat([lp_20ips_2016[\"Time stamp\"], lp_20ips_2016.iloc[:, -7:] ], axis=1)\n",
        "    test_2017_full = pd.concat([lp_30ips_2017[\"Time stamp\"], lp_30ips_2017.iloc[:, -8:] ], axis=1)\n",
        "\n",
        "    train_2016_training_data = train_2016_full[train_2016_full[\"Time stamp\"].dt.month <= 8]\n",
        "    train_2016_val_data = train_2016_full[train_2016_full[\"Time stamp\"].dt.month > 8]\n",
        "\n",
        "    test_2016_training_data = test_2016_full[test_2016_full[\"Time stamp\"].dt.month <= 8]\n",
        "    test_2016_test_data = test_2016_full[test_2016_full[\"Time stamp\"].dt.month > 8]\n",
        "\n",
        "    train_2017_training_data = train_2017_full[train_2017_full[\"Time stamp\"].dt.month <= 8]\n",
        "    train_2017_val_data = train_2017_full[train_2017_full[\"Time stamp\"].dt.month > 8]\n",
        "\n",
        "    test_2017_training_data = test_2017_full[test_2017_full[\"Time stamp\"].dt.month <= 8]\n",
        "    test_2017_test_data = test_2017_full[test_2017_full[\"Time stamp\"].dt.month > 8]\n",
        "\n",
        "    train_2016_training_data.to_csv(\"tune/2016_train.csv\", index=False)\n",
        "    train_2016_val_data.to_csv(\"tune/2016_val.csv\", index=False)\n",
        "    test_2016_training_data.to_csv(\"test/2016_train.csv\", index=False)\n",
        "    test_2016_test_data.to_csv(\"test/2016_test.csv\", index=False)\n",
        "\n",
        "    train_2017_training_data.to_csv(\"tune/2017_train.csv\", index=False)\n",
        "    train_2017_val_data.to_csv(\"tune/2017_val.csv\", index=False)\n",
        "    test_2017_training_data.to_csv(\"test/2017_train.csv\", index=False)\n",
        "    test_2017_test_data.to_csv(\"test/2017_test.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_test_split()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "id": "RUrvBIX3hvmi",
        "outputId": "412cc536-cea4-4b7d-fda7-37d0c4df5e9e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "np.float64(1.3352307434976363)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from abc import ABC, abstractmethod\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sktime.datasets import load_airline\n",
        "from sktime.forecasting.base import ForecastingHorizon\n",
        "from sktime.forecasting.theta import ThetaForecaster\n",
        "from sktime.performance_metrics.forecasting import mean_absolute_percentage_error\n",
        "from sktime.split import temporal_train_test_split\n",
        "\n",
        "class Forecaster(ABC):\n",
        "    def __init__(self, year: int, ig: int, fh: int):\n",
        "        self.train_data, self.val_data = self.load_data(year, ig)\n",
        "        self.fh = fh\n",
        "\n",
        "    @staticmethod\n",
        "    def load_data(year: int, ig: int) -> tuple[pd.DataFrame, pd.DataFrame]:\n",
        "        if year == 2017:\n",
        "            ig_str = f\"LG {ig:02d}\"\n",
        "        else:\n",
        "            ig_str = f\"LG {ig:01d}\"\n",
        "\n",
        "        train = pd.read_csv(f\"tune/{year}_train.csv\")\n",
        "        train_data = train[[\"Time stamp\", ig_str]]\n",
        "        train_data.loc[:, ig_str] = train_data[ig_str].astype(float)\n",
        "        train_data.columns = [\"Time stamp\", \"target\"]\n",
        "\n",
        "        val = pd.read_csv(f\"tune/{year}_val.csv\")\n",
        "        val_data = val[[\"Time stamp\", ig_str]]\n",
        "        val_data.loc[:, ig_str] = val_data[ig_str].astype(float)\n",
        "        val_data.columns = [\"Time stamp\", \"target\"]\n",
        "\n",
        "        return train_data, val_data\n",
        "\n",
        "    @abstractmethod\n",
        "    def preprocess(self):\n",
        "        raise\n",
        "\n",
        "    @abstractmethod\n",
        "    def train(self):\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def predict(self):\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def update(self, value: float):\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def validate(self):\n",
        "        pass\n",
        "\n",
        "\n",
        "class SimpleForecaster(Forecaster):\n",
        "    def __init__(self, year, ig, peak_threshold: float = 0.85, fh: int = 1):\n",
        "        super().__init__(year, ig, fh)\n",
        "        self.peak_threshold = peak_threshold\n",
        "\n",
        "        self.mean = self.train_data[\"target\"].mean()\n",
        "        self.std = self.train_data[\"target\"].std()\n",
        "        self.peak_value = self.train_data[\"target\"].max() * self.peak_threshold\n",
        "        self.normalized_peak_vaue = (self.peak_value - self.mean) / self.std\n",
        "\n",
        "        self.forecaster = ThetaForecaster(sp=48) \n",
        "        self.sk_fh = ForecastingHorizon(self.fh, is_relative=False)\n",
        "\n",
        "    def preprocess(self):\n",
        "        \"\"\"Data cleaning and normalization\"\"\"\n",
        "        self.train_data.loc[:, \"target\"] = self.train_data.loc[:, \"target\"].interpolate()\n",
        "        self.val_data.loc[:, \"target\"] = self.val_data.loc[:, \"target\"].interpolate()\n",
        "\n",
        "        self.train_data = self.train_data.dropna(subset=[\"target\"])\n",
        "        self.val_data = self.val_data.dropna(subset=[\"target\"])\n",
        "\n",
        "        self.train_data.loc[:, \"target_normalized\"] = (self.train_data.loc[:, \"target\"] - self.mean) / self.std\n",
        "        self.train_data.loc[:, \"is_peak\"] = (self.train_data.loc[:, \"target_normalized\"] >= self.normalized_peak_vaue).astype(int)\n",
        "\n",
        "    def train(self):\n",
        "        \"\"\"Fit the internal model(s)\"\"\"\n",
        "        self.forecaster.fit(self.train_data[\"target\"], fh=self.sk_fh)\n",
        "\n",
        "    def predict(self):\n",
        "        \"\"\"Predict the next value(s)\"\"\"\n",
        "        return self.forecaster.predict(self.sk_fh)\n",
        "\n",
        "    def update(self, value: float):\n",
        "        \"\"\"Update the model with the new value (if required)\"\"\"\n",
        "        pass\n",
        "    \n",
        "    def validate(self):\n",
        "        \"\"\"Validate the model on the validation data\"\"\"\n",
        "        errors = []\n",
        "\n",
        "        for y_target in self.val_data.loc[:100, \"target\"]:\n",
        "            y_hat = self.predict()\n",
        "\n",
        "            # de-normalize\n",
        "            y_hat_denormalized = y_hat * self.std + self.mean\n",
        "            \n",
        "            # TODO plug in actual validation error metric\n",
        "            error = mean_absolute_percentage_error(np.array([y_target]), y_hat_denormalized)\n",
        "\n",
        "            errors.append(error)\n",
        "\n",
        "            self.update(y_target)\n",
        "        \n",
        "        return np.mean(errors)\n",
        "\n",
        "\n",
        "forecaster = SimpleForecaster(\n",
        "    year=2017,\n",
        "    ig=1,\n",
        ")\n",
        "forecaster.preprocess()\n",
        "forecaster.train()\n",
        "forecaster.validate()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
