{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 233
    },
    "id": "frfor6Q_gryv",
    "outputId": "8699026f-9805-4689-d823-9d570b422a95"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def train_test_split():\n",
    "    lp_20ips_2016 = pd.read_csv(\"LoadProfile_20IPs_2016.csv\", sep=\";\", skiprows=1)\n",
    "    lp_30ips_2017 = pd.read_csv(\"LoadProfile_30IPs_2017.csv\", sep=\";\", skiprows=1)\n",
    "\n",
    "    lp_20ips_2016[\"Time stamp\"] = lp_20ips_2016[\"Time stamp\"].str.replace(r'[^0-9.: ]', '', regex=True).str.strip()\n",
    "    lp_20ips_2016[\"Time stamp\"] = pd.to_datetime(lp_20ips_2016.loc[:, \"Time stamp\"], format='%d.%m.%Y %H:%M:%S')\n",
    "\n",
    "    lp_30ips_2017[\"Time stamp\"] = lp_30ips_2017[\"Time stamp\"].str.replace(r'[^0-9.: ]', '', regex=True).str.strip()\n",
    "    lp_30ips_2017[\"Time stamp\"] = pd.to_datetime(lp_30ips_2017.loc[:, \"Time stamp\"], format='%d.%m.%Y %H:%M:%S')\n",
    "\n",
    "    train_2016_full = lp_20ips_2016.iloc[:, :-7]\n",
    "    train_2017_full = lp_30ips_2017.iloc[:, :-8]\n",
    "    test_2016_full = pd.concat([lp_20ips_2016[\"Time stamp\"], lp_20ips_2016.iloc[:, -7:] ], axis=1)\n",
    "    test_2017_full = pd.concat([lp_30ips_2017[\"Time stamp\"], lp_30ips_2017.iloc[:, -8:] ], axis=1)\n",
    "\n",
    "    train_2016_training_data = train_2016_full[train_2016_full[\"Time stamp\"].dt.month <= 8]\n",
    "    train_2016_val_data = train_2016_full[train_2016_full[\"Time stamp\"].dt.month > 8]\n",
    "\n",
    "    test_2016_training_data = test_2016_full[test_2016_full[\"Time stamp\"].dt.month <= 8]\n",
    "    test_2016_test_data = test_2016_full[test_2016_full[\"Time stamp\"].dt.month > 8]\n",
    "\n",
    "    train_2017_training_data = train_2017_full[train_2017_full[\"Time stamp\"].dt.month <= 8]\n",
    "    train_2017_val_data = train_2017_full[train_2017_full[\"Time stamp\"].dt.month > 8]\n",
    "\n",
    "    test_2017_training_data = test_2017_full[test_2017_full[\"Time stamp\"].dt.month <= 8]\n",
    "    test_2017_test_data = test_2017_full[test_2017_full[\"Time stamp\"].dt.month > 8]\n",
    "\n",
    "    train_2016_training_data.to_csv(\"tune/2016_train.csv\", index=False)\n",
    "    train_2016_val_data.to_csv(\"tune/2016_val.csv\", index=False)\n",
    "    test_2016_training_data.to_csv(\"test/2016_train.csv\", index=False)\n",
    "    test_2016_test_data.to_csv(\"test/2016_test.csv\", index=False)\n",
    "\n",
    "    train_2017_training_data.to_csv(\"tune/2017_train.csv\", index=False)\n",
    "    train_2017_val_data.to_csv(\"tune/2017_val.csv\", index=False)\n",
    "    test_2017_training_data.to_csv(\"test/2017_train.csv\", index=False)\n",
    "    test_2017_test_data.to_csv(\"test/2017_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 233
    },
    "id": "RUrvBIX3hvmi",
    "outputId": "412cc536-cea4-4b7d-fda7-37d0c4df5e9e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1.4025938639792628)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sktime.datasets import load_airline\n",
    "from sktime.forecasting.base import ForecastingHorizon\n",
    "from sktime.forecasting.theta import ThetaForecaster\n",
    "from sktime.performance_metrics.forecasting import mean_absolute_percentage_error\n",
    "from sktime.split import temporal_train_test_split\n",
    "\n",
    "class Forecaster(ABC):\n",
    "    def __init__(self, year: int, ig: int, fh: int):\n",
    "        self.train_data, self.val_data = self.load_data(year, ig)\n",
    "        self.fh = fh\n",
    "\n",
    "    @staticmethod\n",
    "    def load_data(year: int, ig: int) -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "        if year == 2017:\n",
    "            ig_str = f\"LG {ig:02d}\"\n",
    "        else:\n",
    "            ig_str = f\"LG {ig:01d}\"\n",
    "\n",
    "        train = pd.read_csv(f\"tune/{year}_train.csv\")\n",
    "        train_data = train[[\"Time stamp\", ig_str]]\n",
    "        train_data.loc[:, ig_str] = train_data[ig_str].astype(float)\n",
    "        train_data.columns = [\"Time stamp\", \"target\"]\n",
    "\n",
    "        val = pd.read_csv(f\"tune/{year}_val.csv\")\n",
    "        val_data = val[[\"Time stamp\", ig_str]]\n",
    "        val_data.loc[:, ig_str] = val_data[ig_str].astype(float)\n",
    "        val_data.columns = [\"Time stamp\", \"target\"]\n",
    "\n",
    "        return train_data, val_data\n",
    "\n",
    "    @abstractmethod\n",
    "    def preprocess(self):\n",
    "        raise\n",
    "\n",
    "    @abstractmethod\n",
    "    def train(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def predict(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def update(self, y_target):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def validate(self):\n",
    "        pass\n",
    "\n",
    "class SimpleForecaster(Forecaster):\n",
    "    def __init__(self, year, ig, peak_threshold: float = 0.85, fh: int = 1):\n",
    "        super().__init__(year, ig, fh)\n",
    "        self.peak_threshold = peak_threshold\n",
    "\n",
    "        self.mean = self.train_data[\"target\"].mean()\n",
    "        self.std = self.train_data[\"target\"].std()\n",
    "        self.peak_value = self.train_data[\"target\"].max() * self.peak_threshold\n",
    "        self.normalized_peak_vaue = (self.peak_value - self.mean) / self.std\n",
    "\n",
    "        self.forecaster = ThetaForecaster(sp=672) \n",
    "        self.sk_fh = ForecastingHorizon(range(self.fh), is_relative=False)\n",
    "\n",
    "    def preprocess(self):\n",
    "        \"\"\"Data cleaning and normalization\"\"\"\n",
    "        self.train_data.loc[:, \"target\"] = self.train_data.loc[:, \"target\"].interpolate()\n",
    "        self.val_data.loc[:, \"target\"] = self.val_data.loc[:, \"target\"].interpolate()\n",
    "\n",
    "        self.train_data = self.train_data.dropna(subset=[\"target\"])\n",
    "        self.val_data = self.val_data.dropna(subset=[\"target\"])\n",
    "\n",
    "        self.train_data.loc[:, \"target_normalized\"] = (self.train_data.loc[:, \"target\"] - self.mean) / self.std\n",
    "        self.train_data.loc[:, \"is_peak\"] = (self.train_data.loc[:, \"target_normalized\"] >= self.normalized_peak_vaue).astype(int)\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"Fit the internal model(s)\"\"\"\n",
    "        self.forecaster.fit(self.train_data[\"target\"], fh=self.sk_fh)\n",
    "\n",
    "    def predict(self):\n",
    "        \"\"\"Predict the next value(s)\"\"\"\n",
    "        return self.forecaster.predict(self.sk_fh)\n",
    "\n",
    "    def update(self, y_target):\n",
    "        \"\"\"Update the model with the new value (if required)\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def validate(self):\n",
    "        \"\"\"Validate the model on the validation data\"\"\"\n",
    "        errors = []\n",
    "\n",
    "        # iterate over validation target using sliding window\n",
    "        for i_start in range(0, len(self.val_data), self.fh):\n",
    "            y_target = self.val_data.loc[i_start : i_start + self.fh - 1, \"target\"]\n",
    "            if len(y_target) < self.fh:\n",
    "                break\n",
    "\n",
    "            y_hat = self.predict()\n",
    "\n",
    "            # de-normalize\n",
    "            y_hat_denormalized = y_hat * self.std + self.mean\n",
    "            \n",
    "            # TODO plug in actual validation error metric\n",
    "            error = mean_absolute_percentage_error(y_target, y_hat_denormalized)\n",
    "\n",
    "            errors.append(error)\n",
    "\n",
    "            self.update(y_target)\n",
    "        \n",
    "        return np.mean(errors)\n",
    "\n",
    "\n",
    "forecaster = SimpleForecaster(\n",
    "    year=2017,\n",
    "    ig=1,\n",
    "    fh=48\n",
    ")\n",
    "forecaster.preprocess()\n",
    "forecaster.train()\n",
    "forecaster.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "AVAILABLE_DATASETS = {\n",
    "    2016: range(1, 14),\n",
    "    2017: range(1, 23),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        39\n",
      "1        41\n",
      "2        39\n",
      "3        40\n",
      "4        39\n",
      "         ..\n",
      "23419    18\n",
      "23420    19\n",
      "23421    18\n",
      "23422    18\n",
      "23423    37\n",
      "Name: target, Length: 23424, dtype: int64\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Multiplicative seasonality is not appropriate for zero and negative values",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[14], line 19\u001B[0m\n\u001B[1;32m     15\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m   \u001B[38;5;66;03m# DEBUG\u001B[39;00m\n\u001B[1;32m     17\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39mmean(errors)\n\u001B[0;32m---> 19\u001B[0m \u001B[43mevaluate_forecaster\u001B[49m\u001B[43m(\u001B[49m\u001B[43mSimpleForecaster\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[14], line 11\u001B[0m, in \u001B[0;36mevaluate_forecaster\u001B[0;34m(forecaster_cls)\u001B[0m\n\u001B[1;32m      6\u001B[0m forecaster \u001B[38;5;241m=\u001B[39m forecaster_cls(\n\u001B[1;32m      7\u001B[0m     year\u001B[38;5;241m=\u001B[39myear,\n\u001B[1;32m      8\u001B[0m     ig\u001B[38;5;241m=\u001B[39mig,\n\u001B[1;32m      9\u001B[0m )\n\u001B[1;32m     10\u001B[0m forecaster\u001B[38;5;241m.\u001B[39mpreprocess()\n\u001B[0;32m---> 11\u001B[0m \u001B[43mforecaster\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     12\u001B[0m error \u001B[38;5;241m=\u001B[39m forecaster\u001B[38;5;241m.\u001B[39mvalidate()\n\u001B[1;32m     13\u001B[0m errors\u001B[38;5;241m.\u001B[39mappend(error)\n",
      "Cell \u001B[0;32mIn[13], line 82\u001B[0m, in \u001B[0;36mSimpleForecaster.train\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     80\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Fit the internal model(s)\"\"\"\u001B[39;00m\n\u001B[1;32m     81\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrain_data[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtarget\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[0;32m---> 82\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforecaster\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_data\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtarget\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfh\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msk_fh\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/aigrid/lib/python3.11/site-packages/sktime/forecasting/base/_base.py:394\u001B[0m, in \u001B[0;36mBaseForecaster.fit\u001B[0;34m(self, y, X, fh)\u001B[0m\n\u001B[1;32m    392\u001B[0m \u001B[38;5;66;03m# we call the ordinary _fit if no looping/vectorization needed\u001B[39;00m\n\u001B[1;32m    393\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m vectorization_needed:\n\u001B[0;32m--> 394\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit\u001B[49m\u001B[43m(\u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my_inner\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX_inner\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfh\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfh\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    395\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    396\u001B[0m     \u001B[38;5;66;03m# otherwise we call the vectorized version of fit\u001B[39;00m\n\u001B[1;32m    397\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_vectorize(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfit\u001B[39m\u001B[38;5;124m\"\u001B[39m, y\u001B[38;5;241m=\u001B[39my_inner, X\u001B[38;5;241m=\u001B[39mX_inner, fh\u001B[38;5;241m=\u001B[39mfh)\n",
      "File \u001B[0;32m~/anaconda3/envs/aigrid/lib/python3.11/site-packages/sktime/forecasting/theta.py:141\u001B[0m, in \u001B[0;36mThetaForecaster._fit\u001B[0;34m(self, y, X, fh)\u001B[0m\n\u001B[1;32m    139\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdeseasonalize:\n\u001B[1;32m    140\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdeseasonalizer_ \u001B[38;5;241m=\u001B[39m Deseasonalizer(sp\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msp, model\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmultiplicative\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 141\u001B[0m     y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdeseasonalizer_\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_transform\u001B[49m\u001B[43m(\u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    143\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minitialization_method \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mknown\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minitial_level \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mestimated\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    144\u001B[0m \u001B[38;5;66;03m# fit exponential smoothing forecaster\u001B[39;00m\n\u001B[1;32m    145\u001B[0m \u001B[38;5;66;03m# find theta lines: Theta lines are just SES + drift\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/aigrid/lib/python3.11/site-packages/sktime/transformations/base.py:718\u001B[0m, in \u001B[0;36mBaseTransformer.fit_transform\u001B[0;34m(self, X, y)\u001B[0m\n\u001B[1;32m    644\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Fit to data, then transform it.\u001B[39;00m\n\u001B[1;32m    645\u001B[0m \n\u001B[1;32m    646\u001B[0m \u001B[38;5;124;03mFits the transformer to X and y and returns a transformed version of X.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    714\u001B[0m \u001B[38;5;124;03m        Example: i-th instance of the output is the i-th window running over `X`\u001B[39;00m\n\u001B[1;32m    715\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    716\u001B[0m \u001B[38;5;66;03m# Non-optimized default implementation; override when a better\u001B[39;00m\n\u001B[1;32m    717\u001B[0m \u001B[38;5;66;03m# method is possible for a given algorithm.\u001B[39;00m\n\u001B[0;32m--> 718\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mtransform(X, y)\n",
      "File \u001B[0;32m~/anaconda3/envs/aigrid/lib/python3.11/site-packages/sktime/transformations/base.py:512\u001B[0m, in \u001B[0;36mBaseTransformer.fit\u001B[0;34m(self, X, y)\u001B[0m\n\u001B[1;32m    510\u001B[0m \u001B[38;5;66;03m# we call the ordinary _fit if no looping/vectorization needed\u001B[39;00m\n\u001B[1;32m    511\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m vectorization_needed:\n\u001B[0;32m--> 512\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX_inner\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my_inner\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    513\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    514\u001B[0m     \u001B[38;5;66;03m# otherwise we call the vectorized version of fit\u001B[39;00m\n\u001B[1;32m    515\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_vectorize(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfit\u001B[39m\u001B[38;5;124m\"\u001B[39m, X\u001B[38;5;241m=\u001B[39mX_inner, y\u001B[38;5;241m=\u001B[39my_inner)\n",
      "File \u001B[0;32m~/anaconda3/envs/aigrid/lib/python3.11/site-packages/sktime/transformations/series/detrend/_deseasonalize.py:134\u001B[0m, in \u001B[0;36mDeseasonalizer._fit\u001B[0;34m(self, X, y)\u001B[0m\n\u001B[1;32m    131\u001B[0m sp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msp\n\u001B[1;32m    133\u001B[0m \u001B[38;5;66;03m# apply seasonal decomposition\u001B[39;00m\n\u001B[0;32m--> 134\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mseasonal_ \u001B[38;5;241m=\u001B[39m \u001B[43mseasonal_decompose\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    135\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    136\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    137\u001B[0m \u001B[43m    \u001B[49m\u001B[43mperiod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msp\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    138\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfilt\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    139\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtwo_sided\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    140\u001B[0m \u001B[43m    \u001B[49m\u001B[43mextrapolate_trend\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    141\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mseasonal\u001B[38;5;241m.\u001B[39miloc[:sp]\n\u001B[1;32m    142\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[0;32m~/anaconda3/envs/aigrid/lib/python3.11/site-packages/statsmodels/tsa/seasonal.py:157\u001B[0m, in \u001B[0;36mseasonal_decompose\u001B[0;34m(x, model, filt, period, two_sided, extrapolate_trend)\u001B[0m\n\u001B[1;32m    155\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m model\u001B[38;5;241m.\u001B[39mstartswith(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mm\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m    156\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m np\u001B[38;5;241m.\u001B[39many(x \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m):\n\u001B[0;32m--> 157\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    158\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMultiplicative seasonality is not appropriate \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    159\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfor zero and negative values\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    160\u001B[0m         )\n\u001B[1;32m    162\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m period \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    163\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m pfreq \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mValueError\u001B[0m: Multiplicative seasonality is not appropriate for zero and negative values"
     ]
    }
   ],
   "source": [
    "def evaluate_forecaster(forecaster_cls):\n",
    "    errors = []\n",
    "\n",
    "    for year, igs in AVAILABLE_DATASETS.items():\n",
    "        for ig in igs:\n",
    "            forecaster = forecaster_cls(\n",
    "                year=year,\n",
    "                ig=ig,\n",
    "            )\n",
    "            forecaster.preprocess()\n",
    "            forecaster.train()\n",
    "            error = forecaster.validate()\n",
    "            errors.append(error)\n",
    "            break   # DEBUG\n",
    "        break   # DEBUG\n",
    "\n",
    "    return np.mean(errors)\n",
    "\n",
    "evaluate_forecaster(SimpleForecaster)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
