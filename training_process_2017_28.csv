epoch,train_loss,val_loss
0,0.13544249562496807,0.9069442591790495
1,0.04559646733437205,0.7995377275450476
2,0.04668145980719152,0.49408556405326415
3,0.03741295695132219,0.3453977036065069
4,0.03348491996619685,0.2605188029593435
5,0.0318674036831248,0.13518323500094742
6,0.02892279934383756,0.15070784431079337
7,0.028085500871805797,0.12631156373897504
8,0.026717780448443217,0.14262953691569896
9,0.025576832815473516,0.1423731926892852
10,0.02539900931863383,0.15403381015720038
11,0.02664781247768651,0.22086332414684626
12,0.026321435871794686,0.1468334824746025
13,0.0243879000883742,0.11492299166957623
14,0.023558814633046668,0.11579147273963639
15,0.02319883751233047,0.1291264013515721
16,0.022595438355855552,0.11042864762953129
17,0.02173165752720121,0.11202808201056103
18,0.02241419719900677,0.2724573540019578
19,0.02212232671704628,0.10302194302323564
20,0.021953719236461344,0.1003727977469178
21,0.021336254431349816,0.09724377906271096
22,0.022314277905871205,0.11215295501631395
23,0.02128457362844929,0.07949584642232492
24,0.02073015579405953,0.10506905440305328
25,0.020693306088408765,0.0958284676065606
26,0.020761107853441325,0.11365711355423616
27,0.020706949705248865,0.09532141878127245
28,0.02055496729418801,0.11053177782041193
29,0.021104694488270917,0.14827243473061014
30,0.022207577370600886,0.09737027250367272
31,0.021292716148480356,0.08912910680818771
32,0.020436435652755533,0.11401496280775557
33,0.020172452248435196,0.13821941727149786
34,0.02012495058449112,0.14909585541673995
35,0.020040954781892138,0.1642421682784819
36,0.019893941263606475,0.16496691856294549
37,0.019935977268423742,0.14786418427629813
38,0.01973518106474805,0.13268262450072188
39,0.019549577093108055,0.1495324553905188
40,0.019157056048450298,0.15754942112943923
