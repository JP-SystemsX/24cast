{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/JP-SystemsX/24cast/blob/master/AI_Grid_Hackathon_JP_DEV.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "5tt36fSBdgEb",
    "ExecuteTime": {
     "end_time": "2024-09-11T01:40:41.305838800Z",
     "start_time": "2024-09-11T01:38:18.260334800Z"
    },
    "outputId": "8244cc3f-1ef9-4e9e-dc64-e5790f718a0c",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  Preparing metadata (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Building wheel for wget (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m60.4/60.4 kB\u001B[0m \u001B[31m1.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m138.0/138.0 kB\u001B[0m \u001B[31m6.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m43.6/43.6 kB\u001B[0m \u001B[31m3.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25h  Preparing metadata (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Preparing metadata (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m50.4/50.4 kB\u001B[0m \u001B[31m2.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m117.0/117.0 kB\u001B[0m \u001B[31m8.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25h  Preparing metadata (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m134.8/134.8 kB\u001B[0m \u001B[31m11.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m259.5/259.5 kB\u001B[0m \u001B[31m18.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25h  Preparing metadata (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m234.8/234.8 kB\u001B[0m \u001B[31m18.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m63.4/63.4 kB\u001B[0m \u001B[31m5.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m428.0/428.0 kB\u001B[0m \u001B[31m27.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m312.1/312.1 kB\u001B[0m \u001B[31m24.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m148.2/148.2 kB\u001B[0m \u001B[31m12.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m64.6/64.6 kB\u001B[0m \u001B[31m6.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.5/1.5 MB\u001B[0m \u001B[31m51.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m244.2/244.2 kB\u001B[0m \u001B[31m21.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m139.2/139.2 kB\u001B[0m \u001B[31m12.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m98.7/98.7 MB\u001B[0m \u001B[31m7.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m84.0/84.0 kB\u001B[0m \u001B[31m7.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m85.5/85.5 kB\u001B[0m \u001B[31m7.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.1/3.1 MB\u001B[0m \u001B[31m76.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m808.5/808.5 kB\u001B[0m \u001B[31m44.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m47.6/47.6 kB\u001B[0m \u001B[31m4.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m410.5/410.5 kB\u001B[0m \u001B[31m29.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m79.3/79.3 kB\u001B[0m \u001B[31m5.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m52.7/52.7 kB\u001B[0m \u001B[31m4.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m410.0/410.0 kB\u001B[0m \u001B[31m27.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m141.9/141.9 kB\u001B[0m \u001B[31m10.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m4.5/4.5 MB\u001B[0m \u001B[31m72.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m812.3/812.3 kB\u001B[0m \u001B[31m48.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m115.3/115.3 kB\u001B[0m \u001B[31m10.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m65.1/65.1 MB\u001B[0m \u001B[31m15.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m13.2/13.2 MB\u001B[0m \u001B[31m95.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m38.4/38.4 MB\u001B[0m \u001B[31m16.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m92.0/92.0 kB\u001B[0m \u001B[31m7.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.2/2.2 MB\u001B[0m \u001B[31m60.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m779.1/779.1 MB\u001B[0m \u001B[31m1.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m410.6/410.6 MB\u001B[0m \u001B[31m4.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m14.1/14.1 MB\u001B[0m \u001B[31m39.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m23.7/23.7 MB\u001B[0m \u001B[31m84.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m823.6/823.6 kB\u001B[0m \u001B[31m39.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m731.7/731.7 MB\u001B[0m \u001B[31m2.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m121.6/121.6 MB\u001B[0m \u001B[31m7.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m56.5/56.5 MB\u001B[0m \u001B[31m12.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m124.2/124.2 MB\u001B[0m \u001B[31m7.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m196.0/196.0 MB\u001B[0m \u001B[31m6.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m176.2/176.2 MB\u001B[0m \u001B[31m7.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m99.1/99.1 kB\u001B[0m \u001B[31m7.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m168.1/168.1 MB\u001B[0m \u001B[31m6.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m806.1/806.1 kB\u001B[0m \u001B[31m47.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m7.0/7.0 MB\u001B[0m \u001B[31m109.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m8.8/8.8 MB\u001B[0m \u001B[31m110.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m297.1/297.1 MB\u001B[0m \u001B[31m4.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m12.5/12.5 MB\u001B[0m \u001B[31m69.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m474.3/474.3 kB\u001B[0m \u001B[31m33.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m116.3/116.3 kB\u001B[0m \u001B[31m10.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m13.2/13.2 MB\u001B[0m \u001B[31m64.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.0/3.0 MB\u001B[0m \u001B[31m73.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m39.9/39.9 MB\u001B[0m \u001B[31m21.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m4.5/4.5 MB\u001B[0m \u001B[31m107.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m82.7/82.7 kB\u001B[0m \u001B[31m7.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m101.7/101.7 kB\u001B[0m \u001B[31m9.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.6/3.6 MB\u001B[0m \u001B[31m90.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m6.0/6.0 MB\u001B[0m \u001B[31m109.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m46.0/46.0 kB\u001B[0m \u001B[31m4.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m201.4/201.4 kB\u001B[0m \u001B[31m17.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m134.8/134.8 kB\u001B[0m \u001B[31m12.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m15.9/15.9 MB\u001B[0m \u001B[31m104.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m128.2/128.2 kB\u001B[0m \u001B[31m11.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m194.1/194.1 kB\u001B[0m \u001B[31m16.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m468.9/468.9 kB\u001B[0m \u001B[31m36.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m86.8/86.8 kB\u001B[0m \u001B[31m8.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m19.7/19.7 MB\u001B[0m \u001B[31m92.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m55.3/55.3 kB\u001B[0m \u001B[31m4.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.1/2.1 MB\u001B[0m \u001B[31m85.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25h  Building wheel for nvidia-ml-py3 (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Building wheel for seqeval (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "albumentations 1.4.14 requires scikit-image>=0.21.0, but you have scikit-image 0.20.0 which is incompatible.\n",
      "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\n",
      "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 17.0.0 which is incompatible.\n",
      "osqp 0.6.7.post0 requires scipy!=1.12.0,>=0.13.2, but you have scipy 1.12.0 which is incompatible.\n",
      "torchaudio 2.4.0+cu121 requires torch==2.4.0, but you have torch 2.3.1 which is incompatible.\u001B[0m\u001B[31m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m38.3/38.3 MB\u001B[0m \u001B[31m13.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25h\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 15.0.2 which is incompatible.\u001B[0m\u001B[31m\n",
      "\u001B[0m"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "!pip install -q wget\n",
    "!pip install -q autogluon\n",
    "!pip install -q pyarrow==15.0.2\n",
    "!pip install -q pandas"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!wget https://zenodo.org/records/3899018/files/LoadProfile_20IPs_2016.csv -q\n",
    "!wget https://zenodo.org/records/3899018/files/LoadProfile_30IPs_2017.csv -q"
   ],
   "metadata": {
    "id": "a4GtA99Oe9i8",
    "ExecuteTime": {
     "end_time": "2024-09-11T01:41:04.668267400Z",
     "start_time": "2024-09-11T01:41:04.519640700Z"
    }
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!ls"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CpTArXHNgbwG",
    "outputId": "f73de448-e7d3-4643-dde3-6ba62bb85872",
    "ExecuteTime": {
     "end_time": "2024-09-11T01:52:03.939885800Z",
     "start_time": "2024-09-11T01:52:03.875184100Z"
    }
   },
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "LoadProfile_20IPs_2016.csv  LoadProfile_30IPs_2017.csv\tsample_data\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "from autogluon.timeseries import TimeSeriesDataFrame, TimeSeriesPredictor\n",
    "from pathlib import Path"
   ],
   "metadata": {
    "id": "ePFVg2WIgjFH",
    "ExecuteTime": {
     "end_time": "2024-09-12T08:51:37.664674400Z",
     "start_time": "2024-09-12T08:51:35.853149900Z"
    }
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def train_test_split():\n",
    "    lp_20ips_2016 = pd.read_csv(\"LoadProfile_20IPs_2016.csv\", sep=\";\", skiprows=1)\n",
    "    lp_30ips_2017 = pd.read_csv(\"LoadProfile_30IPs_2017.csv\", sep=\";\", skiprows=1)\n",
    "    Path(\"./tune\").mkdir(exist_ok=True)\n",
    "    Path(\"./test\").mkdir(exist_ok=True)\n",
    "\n",
    "    lp_20ips_2016[\"Time stamp\"] = lp_20ips_2016[\"Time stamp\"].str.replace(r'[^0-9.: ]', '', regex=True).str.strip()\n",
    "    lp_20ips_2016[\"Time stamp\"] = pd.to_datetime(lp_20ips_2016.loc[:, \"Time stamp\"], format='%d.%m.%Y %H:%M:%S')\n",
    "\n",
    "    lp_30ips_2017[\"Time stamp\"] = lp_30ips_2017[\"Time stamp\"].str.replace(r'[^0-9.: ]', '', regex=True).str.strip()\n",
    "    lp_30ips_2017[\"Time stamp\"] = pd.to_datetime(lp_30ips_2017.loc[:, \"Time stamp\"], format='%d.%m.%Y %H:%M:%S')\n",
    "\n",
    "    train_2016_full = lp_20ips_2016.iloc[:, :-7]\n",
    "    train_2017_full = lp_30ips_2017.iloc[:, :-8]\n",
    "    test_2016_full = pd.concat([lp_20ips_2016[\"Time stamp\"], lp_20ips_2016.iloc[:, -7:] ], axis=1)\n",
    "    test_2017_full = pd.concat([lp_30ips_2017[\"Time stamp\"], lp_30ips_2017.iloc[:, -8:] ], axis=1)\n",
    "\n",
    "    train_2016_training_data = train_2016_full[train_2016_full[\"Time stamp\"].dt.month <= 8]\n",
    "    train_2016_val_data = train_2016_full[train_2016_full[\"Time stamp\"].dt.month > 8]\n",
    "\n",
    "    test_2016_training_data = test_2016_full[test_2016_full[\"Time stamp\"].dt.month <= 8]\n",
    "    test_2016_test_data = test_2016_full[test_2016_full[\"Time stamp\"].dt.month > 8]\n",
    "\n",
    "    train_2017_training_data = train_2017_full[train_2017_full[\"Time stamp\"].dt.month <= 8]\n",
    "    train_2017_val_data = train_2017_full[train_2017_full[\"Time stamp\"].dt.month > 8]\n",
    "\n",
    "    test_2017_training_data = test_2017_full[test_2017_full[\"Time stamp\"].dt.month <= 8]\n",
    "    test_2017_test_data = test_2017_full[test_2017_full[\"Time stamp\"].dt.month > 8]\n",
    "\n",
    "    train_2016_training_data.to_csv(\"tune/2016_train.csv\", index=False)\n",
    "    train_2016_val_data.to_csv(\"tune/2016_val.csv\", index=False)\n",
    "    test_2016_training_data.to_csv(\"test/2016_train.csv\", index=False)\n",
    "    test_2016_test_data.to_csv(\"test/2016_test.csv\", index=False)\n",
    "\n",
    "    train_2017_training_data.to_csv(\"tune/2017_train.csv\", index=False)\n",
    "    train_2017_val_data.to_csv(\"tune/2017_val.csv\", index=False)\n",
    "    test_2017_training_data.to_csv(\"test/2017_train.csv\", index=False)\n",
    "    test_2017_test_data.to_csv(\"test/2017_test.csv\", index=False)\n",
    "train_test_split()"
   ],
   "metadata": {
    "id": "miqBMMrPj2pC",
    "ExecuteTime": {
     "end_time": "2024-09-12T07:38:36.831265100Z",
     "start_time": "2024-09-12T07:38:34.679055200Z"
    }
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jimmy\\AppData\\Local\\Temp\\ipykernel_43748\\4077685799.py:21: FutureWarning: DataFrame.interpolate with object dtype is deprecated and will raise in a future version. Call obj.infer_objects(copy=False) before interpolating instead.\n",
      "  df.interpolate(method='linear', inplace=True)\n",
      "C:\\Users\\Jimmy\\AppData\\Local\\Temp\\ipykernel_43748\\4077685799.py:21: FutureWarning: DataFrame.interpolate with object dtype is deprecated and will raise in a future version. Call obj.infer_objects(copy=False) before interpolating instead.\n",
      "  df.interpolate(method='linear', inplace=True)\n",
      "C:\\Users\\Jimmy\\AppData\\Local\\Temp\\ipykernel_43748\\4077685799.py:21: FutureWarning: DataFrame.interpolate with object dtype is deprecated and will raise in a future version. Call obj.infer_objects(copy=False) before interpolating instead.\n",
      "  df.interpolate(method='linear', inplace=True)\n",
      "C:\\Users\\Jimmy\\AppData\\Local\\Temp\\ipykernel_43748\\4077685799.py:21: FutureWarning: DataFrame.interpolate with object dtype is deprecated and will raise in a future version. Call obj.infer_objects(copy=False) before interpolating instead.\n",
      "  df.interpolate(method='linear', inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": "                             target\nitem_id timestamp                  \nLG 1    2016-01-01 00:15:00    39.0\n        2016-01-01 00:30:00    41.0\n        2016-01-01 00:45:00    39.0\n        2016-01-01 01:00:00    40.0\n        2016-01-01 01:15:00    39.0\n...                             ...\nLG 22   2017-08-31 22:45:00     1.5\n        2017-08-31 23:00:00     1.6\n        2017-08-31 23:15:00     1.4\n        2017-08-31 23:30:00     1.0\n        2017-08-31 23:45:00     0.7\n\n[817706 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>target</th>\n    </tr>\n    <tr>\n      <th>item_id</th>\n      <th>timestamp</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">LG 1</th>\n      <th>2016-01-01 00:15:00</th>\n      <td>39.0</td>\n    </tr>\n    <tr>\n      <th>2016-01-01 00:30:00</th>\n      <td>41.0</td>\n    </tr>\n    <tr>\n      <th>2016-01-01 00:45:00</th>\n      <td>39.0</td>\n    </tr>\n    <tr>\n      <th>2016-01-01 01:00:00</th>\n      <td>40.0</td>\n    </tr>\n    <tr>\n      <th>2016-01-01 01:15:00</th>\n      <td>39.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">LG 22</th>\n      <th>2017-08-31 22:45:00</th>\n      <td>1.5</td>\n    </tr>\n    <tr>\n      <th>2017-08-31 23:00:00</th>\n      <td>1.6</td>\n    </tr>\n    <tr>\n      <th>2017-08-31 23:15:00</th>\n      <td>1.4</td>\n    </tr>\n    <tr>\n      <th>2017-08-31 23:30:00</th>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2017-08-31 23:45:00</th>\n      <td>0.7</td>\n    </tr>\n  </tbody>\n</table>\n<p>817706 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_length = 48\n",
    "long_runtime = (3*60-5)*60 # in seconds\n",
    "dev_runtime = 5*60 # in seconds\n",
    "\n",
    "train_1 = pd.read_csv(\"tune/2016_train.csv\")\n",
    "train_2 = pd.read_csv(\"tune/2017_train.csv\")\n",
    "val_1 = pd.read_csv(\"tune/2016_val.csv\")\n",
    "val_2 = pd.read_csv(\"tune/2017_val.csv\")\n",
    "\n",
    "def prepare_AG_data(dfs: list[pd.DataFrame]):\n",
    "    # Prepare Data\n",
    "    melted_dfs = []\n",
    "    for df in dfs:\n",
    "        df = deepcopy(df)#[[\"Time stamp\", \"LG 1\"]]\n",
    "        df.loc[:, [\"Time stamp\"]] = df[\"Time stamp\"].str.replace(r'[^0-9.: ]', '', regex=True).str.strip()\n",
    "        df.loc[:, [\"Time stamp\"]] = pd.to_datetime(df[\"Time stamp\"])\n",
    "        # TODO Normalize Data else MASE means nothing\n",
    "        # Concat Columns & Assign Ids\n",
    "        df = df.melt(id_vars=['Time stamp'], var_name='item_id', value_name='target')\n",
    "        df = df.dropna()\n",
    "        df.interpolate(method='linear', inplace=True)\n",
    "        melted_dfs.append(df)\n",
    "    df = pd.concat(melted_dfs)\n",
    "    df = TimeSeriesDataFrame.from_data_frame(\n",
    "        df,\n",
    "        id_column=\"item_id\",\n",
    "        timestamp_column=\"Time stamp\"\n",
    "    )\n",
    "    return df\n",
    "\n",
    "train = prepare_AG_data([train_1, train_2])\n",
    "val = prepare_AG_data([val_1, val_2])\n",
    "train"
   ],
   "metadata": {
    "id": "5o9Va5z8ITzx",
    "outputId": "eb624851-83e1-46d1-a7ff-18facf5b7190",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 613
    },
    "ExecuteTime": {
     "end_time": "2024-09-12T08:51:41.418403600Z",
     "start_time": "2024-09-12T08:51:39.500388Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"autogluon-m4-hourly\"\n",
      "Beginning AutoGluon training... Time limit = 300s\n",
      "AutoGluon will save models to 'autogluon-m4-hourly'\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.9.13\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22631\n",
      "CPU Count:          12\n",
      "GPU Count:          0\n",
      "Memory Avail:       1.22 GB / 15.34 GB (7.9%)\n",
      "Disk Space Avail:   78.55 GB / 474.72 GB (16.5%)\n",
      "===================================================\n",
      "Setting presets to: medium_quality\n",
      "\n",
      "Fitting with arguments:\n",
      "{'enable_ensemble': True,\n",
      " 'eval_metric': MAPE,\n",
      " 'freq': '15min',\n",
      " 'hyperparameters': 'light',\n",
      " 'known_covariates_names': [],\n",
      " 'num_val_windows': 1,\n",
      " 'prediction_length': 48,\n",
      " 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
      " 'random_seed': 123,\n",
      " 'refit_every_n_windows': 1,\n",
      " 'refit_full': False,\n",
      " 'skip_model_selection': False,\n",
      " 'target': 'target',\n",
      " 'time_limit': 300,\n",
      " 'verbosity': 2}\n",
      "\n",
      "train_data with frequency 'None' has been resampled to frequency '15min'.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "File \u001B[1;32m~\\Documents\\UNI\\Projects\\24cast\\venv\\lib\\site-packages\\joblib\\parallel.py:1650\u001B[0m, in \u001B[0;36mParallel._get_outputs\u001B[1;34m(self, iterator, pre_dispatch)\u001B[0m\n\u001B[0;32m   1649\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend\u001B[38;5;241m.\u001B[39mretrieval_context():\n\u001B[1;32m-> 1650\u001B[0m         \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_retrieve()\n\u001B[0;32m   1652\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mGeneratorExit\u001B[39;00m:\n\u001B[0;32m   1653\u001B[0m     \u001B[38;5;66;03m# The generator has been garbage collected before being fully\u001B[39;00m\n\u001B[0;32m   1654\u001B[0m     \u001B[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001B[39;00m\n\u001B[0;32m   1655\u001B[0m     \u001B[38;5;66;03m# the user if necessary.\u001B[39;00m\n",
      "File \u001B[1;32m~\\Documents\\UNI\\Projects\\24cast\\venv\\lib\\site-packages\\joblib\\parallel.py:1762\u001B[0m, in \u001B[0;36mParallel._retrieve\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1759\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ((\u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m\n\u001B[0;32m   1760\u001B[0m     (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mget_status(\n\u001B[0;32m   1761\u001B[0m         timeout\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtimeout) \u001B[38;5;241m==\u001B[39m TASK_PENDING)):\n\u001B[1;32m-> 1762\u001B[0m     \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1763\u001B[0m     \u001B[38;5;28;01mcontinue\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "File \u001B[1;32m<timed exec>:10\u001B[0m\n",
      "File \u001B[1;32m~\\Documents\\UNI\\Projects\\24cast\\venv\\lib\\site-packages\\autogluon\\core\\utils\\decorators.py:31\u001B[0m, in \u001B[0;36munpack.<locals>._unpack_inner.<locals>._call\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     28\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(f)\n\u001B[0;32m     29\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_call\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m     30\u001B[0m     gargs, gkwargs \u001B[38;5;241m=\u001B[39m g(\u001B[38;5;241m*\u001B[39mother_args, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m---> 31\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m f(\u001B[38;5;241m*\u001B[39mgargs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mgkwargs)\n",
      "File \u001B[1;32m~\\Documents\\UNI\\Projects\\24cast\\venv\\lib\\site-packages\\autogluon\\timeseries\\predictor.py:701\u001B[0m, in \u001B[0;36mTimeSeriesPredictor.fit\u001B[1;34m(self, train_data, tuning_data, time_limit, presets, hyperparameters, hyperparameter_tune_kwargs, excluded_model_types, num_val_windows, val_step_size, refit_every_n_windows, refit_full, enable_ensemble, skip_model_selection, random_seed, verbosity)\u001B[0m\n\u001B[0;32m    698\u001B[0m logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mFitting with arguments:\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    699\u001B[0m logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpprint\u001B[38;5;241m.\u001B[39mpformat({k:\u001B[38;5;250m \u001B[39mv\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mfor\u001B[39;00m\u001B[38;5;250m \u001B[39mk,\u001B[38;5;250m \u001B[39mv\u001B[38;5;250m \u001B[39m\u001B[38;5;129;01min\u001B[39;00m\u001B[38;5;250m \u001B[39mfit_args\u001B[38;5;241m.\u001B[39mitems()\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mif\u001B[39;00m\u001B[38;5;250m \u001B[39mv\u001B[38;5;250m \u001B[39m\u001B[38;5;129;01mis\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;129;01mnot\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m})\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 701\u001B[0m train_data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_check_and_prepare_data_frame\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_data\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtrain_data\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    702\u001B[0m logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mProvided train_data has \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_dataset_stats(train_data)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    704\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m val_step_size \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32m~\\Documents\\UNI\\Projects\\24cast\\venv\\lib\\site-packages\\autogluon\\timeseries\\predictor.py:316\u001B[0m, in \u001B[0;36mTimeSeriesPredictor._check_and_prepare_data_frame\u001B[1;34m(self, data, name)\u001B[0m\n\u001B[0;32m    314\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m df\u001B[38;5;241m.\u001B[39mfreq \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfreq:\n\u001B[0;32m    315\u001B[0m         logger\u001B[38;5;241m.\u001B[39mwarning(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m with frequency \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdf\u001B[38;5;241m.\u001B[39mfreq\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m has been resampled to frequency \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfreq\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 316\u001B[0m         df \u001B[38;5;241m=\u001B[39m \u001B[43mdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert_frequency\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfreq\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfreq\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    317\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m df\n",
      "File \u001B[1;32m~\\Documents\\UNI\\Projects\\24cast\\venv\\lib\\site-packages\\autogluon\\timeseries\\dataset\\ts_dataframe.py:1002\u001B[0m, in \u001B[0;36mTimeSeriesDataFrame.convert_frequency\u001B[1;34m(self, freq, agg_numeric, agg_categorical, num_cpus, chunk_size, **kwargs)\u001B[0m\n\u001B[0;32m    999\u001B[0m \u001B[38;5;66;03m# Resampling time for 1 item < overhead time for a single parallel job. Therefore, we group items into chunks\u001B[39;00m\n\u001B[0;32m   1000\u001B[0m \u001B[38;5;66;03m# so that the speedup from parallelization isn't dominated by the communication costs.\u001B[39;00m\n\u001B[0;32m   1001\u001B[0m chunks \u001B[38;5;241m=\u001B[39m split_into_chunks(pd\u001B[38;5;241m.\u001B[39mDataFrame(\u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39mgroupby(level\u001B[38;5;241m=\u001B[39mITEMID, sort\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m), chunk_size)\n\u001B[1;32m-> 1002\u001B[0m resampled_chunks \u001B[38;5;241m=\u001B[39m \u001B[43mParallel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_cpus\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresample_chunk\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[43mchunk\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mchunk\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mchunks\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1003\u001B[0m resampled_df \u001B[38;5;241m=\u001B[39m TimeSeriesDataFrame(pd\u001B[38;5;241m.\u001B[39mconcat(resampled_chunks))\n\u001B[0;32m   1004\u001B[0m resampled_df\u001B[38;5;241m.\u001B[39mstatic_features \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstatic_features\n",
      "File \u001B[1;32m~\\Documents\\UNI\\Projects\\24cast\\venv\\lib\\site-packages\\joblib\\parallel.py:2007\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   2001\u001B[0m \u001B[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001B[39;00m\n\u001B[0;32m   2002\u001B[0m \u001B[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001B[39;00m\n\u001B[0;32m   2003\u001B[0m \u001B[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001B[39;00m\n\u001B[0;32m   2004\u001B[0m \u001B[38;5;66;03m# dispatch of the tasks to the workers.\u001B[39;00m\n\u001B[0;32m   2005\u001B[0m \u001B[38;5;28mnext\u001B[39m(output)\n\u001B[1;32m-> 2007\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m output \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreturn_generator \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43moutput\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\UNI\\Projects\\24cast\\venv\\lib\\site-packages\\joblib\\parallel.py:1703\u001B[0m, in \u001B[0;36mParallel._get_outputs\u001B[1;34m(self, iterator, pre_dispatch)\u001B[0m\n\u001B[0;32m   1701\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m:\n\u001B[0;32m   1702\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m-> 1703\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_abort\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1704\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n\u001B[0;32m   1705\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m   1706\u001B[0m     \u001B[38;5;66;03m# Store the unconsumed tasks and terminate the workers if necessary\u001B[39;00m\n",
      "File \u001B[1;32m~\\Documents\\UNI\\Projects\\24cast\\venv\\lib\\site-packages\\joblib\\parallel.py:1614\u001B[0m, in \u001B[0;36mParallel._abort\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1609\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_aborted \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(backend, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mabort_everything\u001B[39m\u001B[38;5;124m'\u001B[39m)):\n\u001B[0;32m   1610\u001B[0m     \u001B[38;5;66;03m# If the backend is managed externally we need to make sure\u001B[39;00m\n\u001B[0;32m   1611\u001B[0m     \u001B[38;5;66;03m# to leave it in a working state to allow for future jobs\u001B[39;00m\n\u001B[0;32m   1612\u001B[0m     \u001B[38;5;66;03m# scheduling.\u001B[39;00m\n\u001B[0;32m   1613\u001B[0m     ensure_ready \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_managed_backend\n\u001B[1;32m-> 1614\u001B[0m     \u001B[43mbackend\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mabort_everything\u001B[49m\u001B[43m(\u001B[49m\u001B[43mensure_ready\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mensure_ready\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1615\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_aborted \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[1;32m~\\Documents\\UNI\\Projects\\24cast\\venv\\lib\\site-packages\\joblib\\_parallel_backends.py:620\u001B[0m, in \u001B[0;36mLokyBackend.abort_everything\u001B[1;34m(self, ensure_ready)\u001B[0m\n\u001B[0;32m    617\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mabort_everything\u001B[39m(\u001B[38;5;28mself\u001B[39m, ensure_ready\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[0;32m    618\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Shutdown the workers and restart a new one with the same parameters\u001B[39;00m\n\u001B[0;32m    619\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 620\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_workers\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mterminate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkill_workers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m    621\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_workers \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    623\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ensure_ready:\n",
      "File \u001B[1;32m~\\Documents\\UNI\\Projects\\24cast\\venv\\lib\\site-packages\\joblib\\executor.py:75\u001B[0m, in \u001B[0;36mMemmappingExecutor.terminate\u001B[1;34m(self, kill_workers)\u001B[0m\n\u001B[0;32m     73\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mterminate\u001B[39m(\u001B[38;5;28mself\u001B[39m, kill_workers\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[1;32m---> 75\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshutdown\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkill_workers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkill_workers\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     77\u001B[0m     \u001B[38;5;66;03m# When workers are killed in a brutal manner, they cannot execute the\u001B[39;00m\n\u001B[0;32m     78\u001B[0m     \u001B[38;5;66;03m# finalizer of their shared memmaps. The refcount of those memmaps may\u001B[39;00m\n\u001B[0;32m     79\u001B[0m     \u001B[38;5;66;03m# be off by an unknown number, so instead of decref'ing them, we force\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     84\u001B[0m     \u001B[38;5;66;03m# with allow_non_empty=True but if we can't, it will be clean up later\u001B[39;00m\n\u001B[0;32m     85\u001B[0m     \u001B[38;5;66;03m# on by the resource_tracker.\u001B[39;00m\n\u001B[0;32m     86\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_submit_resize_lock:\n",
      "File \u001B[1;32m~\\Documents\\UNI\\Projects\\24cast\\venv\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:1303\u001B[0m, in \u001B[0;36mProcessPoolExecutor.shutdown\u001B[1;34m(self, wait, kill_workers)\u001B[0m\n\u001B[0;32m   1299\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m executor_manager_thread \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m wait:\n\u001B[0;32m   1300\u001B[0m     \u001B[38;5;66;03m# This locks avoids concurrent join if the interpreter\u001B[39;00m\n\u001B[0;32m   1301\u001B[0m     \u001B[38;5;66;03m# is shutting down.\u001B[39;00m\n\u001B[0;32m   1302\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m _global_shutdown_lock:\n\u001B[1;32m-> 1303\u001B[0m         \u001B[43mexecutor_manager_thread\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1304\u001B[0m         _threads_wakeups\u001B[38;5;241m.\u001B[39mpop(executor_manager_thread, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m   1306\u001B[0m \u001B[38;5;66;03m# To reduce the risk of opening too many files, remove references to\u001B[39;00m\n\u001B[0;32m   1307\u001B[0m \u001B[38;5;66;03m# objects that use file descriptors.\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\threading.py:1060\u001B[0m, in \u001B[0;36mThread.join\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m   1057\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcannot join current thread\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   1059\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 1060\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_wait_for_tstate_lock\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1061\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1062\u001B[0m     \u001B[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001B[39;00m\n\u001B[0;32m   1063\u001B[0m     \u001B[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001B[39;00m\n\u001B[0;32m   1064\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_wait_for_tstate_lock(timeout\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mmax\u001B[39m(timeout, \u001B[38;5;241m0\u001B[39m))\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\threading.py:1080\u001B[0m, in \u001B[0;36mThread._wait_for_tstate_lock\u001B[1;34m(self, block, timeout)\u001B[0m\n\u001B[0;32m   1077\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[0;32m   1079\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1080\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mlock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43macquire\u001B[49m\u001B[43m(\u001B[49m\u001B[43mblock\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[0;32m   1081\u001B[0m         lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[0;32m   1082\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stop()\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "predictor = TimeSeriesPredictor(\n",
    "    prediction_length=prediction_length,\n",
    "    path=\"autogluon-m4-hourly\",\n",
    "    target=\"target\",\n",
    "    eval_metric=\"MAPE\",\n",
    "    freq=\"15min\"\n",
    ")\n",
    "\n",
    "# Dev Setting\n",
    "predictor = predictor.fit(\n",
    "    train,\n",
    "    presets=\"medium_quality\",\n",
    "    time_limit=dev_runtime,\n",
    ")"
   ],
   "metadata": {
    "id": "1_apvIsLITzy",
    "outputId": "3ef9e86e-926f-4a92-f3e2-4d6f9efb4abb",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "ExecuteTime": {
     "end_time": "2024-09-12T08:35:30.833489200Z",
     "start_time": "2024-09-12T08:35:24.562705700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "data with frequency 'None' has been resampled to frequency '15min'.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Trainer has no fit models that can predict.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[79], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mpredictor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mval\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\UNI\\Projects\\24cast\\venv\\lib\\site-packages\\autogluon\\timeseries\\predictor.py:905\u001B[0m, in \u001B[0;36mTimeSeriesPredictor.evaluate\u001B[1;34m(self, data, model, metrics, display, use_cache)\u001B[0m\n\u001B[0;32m    903\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_and_prepare_data_frame(data)\n\u001B[0;32m    904\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_data_for_evaluation(data)\n\u001B[1;32m--> 905\u001B[0m scores_dict \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_learner\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetrics\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmetrics\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    906\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m display:\n\u001B[0;32m    907\u001B[0m     logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEvaluations on test data:\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\Documents\\UNI\\Projects\\24cast\\venv\\lib\\site-packages\\autogluon\\timeseries\\learner.py:212\u001B[0m, in \u001B[0;36mTimeSeriesLearner.evaluate\u001B[1;34m(self, data, model, metrics, use_cache)\u001B[0m\n\u001B[0;32m    204\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mevaluate\u001B[39m(\n\u001B[0;32m    205\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    206\u001B[0m     data: TimeSeriesDataFrame,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    209\u001B[0m     use_cache: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m    210\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Dict[\u001B[38;5;28mstr\u001B[39m, \u001B[38;5;28mfloat\u001B[39m]:\n\u001B[0;32m    211\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfeature_generator\u001B[38;5;241m.\u001B[39mtransform(data)\n\u001B[1;32m--> 212\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_trainer\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetrics\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmetrics\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\UNI\\Projects\\24cast\\venv\\lib\\site-packages\\autogluon\\timeseries\\trainer\\abstract_trainer.py:942\u001B[0m, in \u001B[0;36mAbstractTimeSeriesTrainer.evaluate\u001B[1;34m(self, data, model, metrics, use_cache)\u001B[0m\n\u001B[0;32m    932\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mevaluate\u001B[39m(\n\u001B[0;32m    933\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    934\u001B[0m     data: TimeSeriesDataFrame,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    937\u001B[0m     use_cache: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m    938\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Dict[\u001B[38;5;28mstr\u001B[39m, \u001B[38;5;28mfloat\u001B[39m]:\n\u001B[0;32m    939\u001B[0m     past_data, known_covariates \u001B[38;5;241m=\u001B[39m data\u001B[38;5;241m.\u001B[39mget_model_inputs_for_scoring(\n\u001B[0;32m    940\u001B[0m         prediction_length\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprediction_length, known_covariates_names\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmetadata\u001B[38;5;241m.\u001B[39mknown_covariates\n\u001B[0;32m    941\u001B[0m     )\n\u001B[1;32m--> 942\u001B[0m     predictions \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpast_data\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mknown_covariates\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mknown_covariates\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    943\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(metrics, \u001B[38;5;28mlist\u001B[39m):  \u001B[38;5;66;03m# a single metric is provided\u001B[39;00m\n\u001B[0;32m    944\u001B[0m         metrics \u001B[38;5;241m=\u001B[39m [metrics]\n",
      "File \u001B[1;32m~\\Documents\\UNI\\Projects\\24cast\\venv\\lib\\site-packages\\autogluon\\timeseries\\trainer\\abstract_trainer.py:895\u001B[0m, in \u001B[0;36mAbstractTimeSeriesTrainer.predict\u001B[1;34m(self, data, known_covariates, model, use_cache, random_seed, **kwargs)\u001B[0m\n\u001B[0;32m    886\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpredict\u001B[39m(\n\u001B[0;32m    887\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    888\u001B[0m     data: TimeSeriesDataFrame,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    893\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m    894\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m TimeSeriesDataFrame:\n\u001B[1;32m--> 895\u001B[0m     model_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_model_for_prediction\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    896\u001B[0m     model_pred_dict \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_model_pred_dict(\n\u001B[0;32m    897\u001B[0m         model_names\u001B[38;5;241m=\u001B[39m[model_name],\n\u001B[0;32m    898\u001B[0m         data\u001B[38;5;241m=\u001B[39mdata,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    901\u001B[0m         random_seed\u001B[38;5;241m=\u001B[39mrandom_seed,\n\u001B[0;32m    902\u001B[0m     )\n\u001B[0;32m    903\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m model_pred_dict[model_name]\n",
      "File \u001B[1;32m~\\Documents\\UNI\\Projects\\24cast\\venv\\lib\\site-packages\\autogluon\\timeseries\\trainer\\abstract_trainer.py:872\u001B[0m, in \u001B[0;36mAbstractTimeSeriesTrainer._get_model_for_prediction\u001B[1;34m(self, model, verbose)\u001B[0m\n\u001B[0;32m    870\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m model \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    871\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel_best \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 872\u001B[0m         best_model_name: \u001B[38;5;28mstr\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_model_best\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    873\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel_best \u001B[38;5;241m=\u001B[39m best_model_name\n\u001B[0;32m    874\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m verbose:\n",
      "File \u001B[1;32m~\\Documents\\UNI\\Projects\\24cast\\venv\\lib\\site-packages\\autogluon\\timeseries\\trainer\\abstract_trainer.py:398\u001B[0m, in \u001B[0;36mAbstractTimeSeriesTrainer.get_model_best\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    396\u001B[0m models \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_model_names()\n\u001B[0;32m    397\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m models:\n\u001B[1;32m--> 398\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTrainer has no fit models that can predict.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    399\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(models) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m    400\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m models[\u001B[38;5;241m0\u001B[39m]\n",
      "\u001B[1;31mValueError\u001B[0m: Trainer has no fit models that can predict."
     ]
    }
   ],
   "source": [
    "predictor.evaluate(val)"
   ],
   "metadata": {
    "id": "fPoRO-ldjfLB",
    "outputId": "64f37812-bdf7-4a97-c66b-12de07a198ee",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "ExecuteTime": {
     "end_time": "2024-09-12T07:38:13.332880800Z",
     "start_time": "2024-09-12T07:38:11.500337700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predictor.leaderboard()"
   ],
   "metadata": {
    "id": "sYUHljj4jfLC",
    "outputId": "b8cb27cd-0700-47e5-84c1-a4568a5431a7",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "ExecuteTime": {
     "start_time": "2024-09-12T07:38:13.332880800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Level UP"
   ],
   "metadata": {
    "collapsed": false,
    "id": "tcE9ZOKtjfLC"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "predictor = TimeSeriesPredictor(\n",
    "    prediction_length=prediction_length,\n",
    "    path=\"autogluon-m4-hourly\",\n",
    "    target=\"target\",\n",
    "    eval_metric=\"MAPE\",\n",
    "    freq=\"15min\"\n",
    ")\n",
    "\n",
    "# TODO Increase Time Limit For Final Version\n",
    "predictor = predictor.fit(\n",
    "    train,\n",
    "    presets=\"best_quality\",\n",
    "    time_limit=long_runtime,\n",
    ")"
   ],
   "metadata": {
    "id": "ygV0MHd5jfLE",
    "outputId": "b6273989-1b8b-4cef-949f-312a9f376be3",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "ExecuteTime": {
     "start_time": "2024-09-12T07:38:13.334553500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(predictor.evaluate(val))\n",
    "predictor.leaderboard()"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-11T14:42:20.080958100Z",
     "start_time": "2024-09-11T14:42:13.316020900Z"
    },
    "id": "LS4Kc4QyjfLE"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Custom Metric \n",
    "from sklearn.metrics import mean_squared_error \n",
    "from autogluon.timeseries.metrics import TimeSeriesScorer\n",
    "class eRMSE(TimeSeriesScorer):\n",
    "\n",
    "    equivalent_tabular_regression_metric = \"root_mean_squared_error\"\n",
    "\n",
    "    def compute_metric(\n",
    "        self, data_future: TimeSeriesDataFrame, predictions: TimeSeriesDataFrame, target: str = \"target\", **kwargs\n",
    "    ) -> float:\n",
    "        y_true, y_pred = self._get_point_forecast_score_inputs(data_future, predictions, target=target)\n",
    "        # We always want to return a val (to do so not 85% of max but 95th percentile)\n",
    "        ext_thr = np.percentile(y_true.dropna(), 95)\n",
    "        mask = y_true > ext_thr\n",
    "        val1 = np.sqrt(self._safemean((y_true[mask] - y_pred[mask]) ** 2))\n",
    "        val2 = np.sqrt(self._safemean((y_true - y_pred) ** 2))\n",
    "        return val1+val2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-12T08:51:54.026688300Z",
     "start_time": "2024-09-12T08:51:54.000857600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Beginning AutoGluon training... Time limit = 300s\n",
      "AutoGluon will save models to 'autogluon-m4-hourly'\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.9.13\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22631\n",
      "CPU Count:          12\n",
      "GPU Count:          0\n",
      "Memory Avail:       1.58 GB / 15.34 GB (10.3%)\n",
      "Disk Space Avail:   75.37 GB / 474.72 GB (15.9%)\n",
      "===================================================\n",
      "Setting presets to: medium_quality\n",
      "\n",
      "Fitting with arguments:\n",
      "{'enable_ensemble': True,\n",
      " 'eval_metric': RMSE,\n",
      " 'freq': '15min',\n",
      " 'hyperparameters': 'light',\n",
      " 'known_covariates_names': [],\n",
      " 'num_val_windows': 1,\n",
      " 'prediction_length': 48,\n",
      " 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
      " 'random_seed': 123,\n",
      " 'refit_every_n_windows': 1,\n",
      " 'refit_full': False,\n",
      " 'skip_model_selection': False,\n",
      " 'target': 'target',\n",
      " 'time_limit': 300,\n",
      " 'verbosity': 2}\n",
      "\n",
      "train_data with frequency 'None' has been resampled to frequency '15min'.\n",
      "Provided train_data has 969962 rows (NaN fraction=15.7%), 31 time series. Median time series length is 23327 (min=23327, max=58463). \n",
      "\n",
      "Provided data contains following columns:\n",
      "\ttarget: 'target'\n",
      "\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'RMSE'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "===================================================\n",
      "\n",
      "Starting training. Start time is 2024-09-12 10:58:12\n",
      "Models that will be trained: ['Naive', 'SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta', 'TemporalFusionTransformer']\n",
      "Training timeseries model Naive. Training for up to 36.8s of the 294.3s of remaining time.\n",
      "\t-15.8370      = Validation score (-RMSE)\n",
      "\t0.91    s     = Training runtime\n",
      "\t5.93    s     = Validation (prediction) runtime\n",
      "Training timeseries model SeasonalNaive. Training for up to 41.1s of the 287.5s of remaining time.\n",
      "\t-15.3251      = Validation score (-RMSE)\n",
      "\t0.95    s     = Training runtime\n",
      "\t0.21    s     = Validation (prediction) runtime\n",
      "Training timeseries model RecursiveTabular. Training for up to 47.7s of the 286.3s of remaining time.\n",
      "\t-58.9130      = Validation score (-RMSE)\n",
      "\t45.36   s     = Training runtime\n",
      "\t5.70    s     = Validation (prediction) runtime\n",
      "Training timeseries model DirectTabular. Training for up to 47.0s of the 235.2s of remaining time.\n",
      "\t-60.0164      = Validation score (-RMSE)\n",
      "\t44.34   s     = Training runtime\n",
      "\t2.88    s     = Validation (prediction) runtime\n",
      "Training timeseries model ETS. Training for up to 47.0s of the 188.0s of remaining time.\n",
      "\tTime limit exceeded... Skipping ETS.\n",
      "Training timeseries model Theta. Training for up to 46.6s of the 139.7s of remaining time.\n",
      "\tTime limit exceeded... Skipping Theta.\n",
      "Training timeseries model TemporalFusionTransformer. Training for up to 45.7s of the 91.3s of remaining time.\n",
      "\t-15.7030      = Validation score (-RMSE)\n",
      "\t46.92   s     = Training runtime\n",
      "\t1.10    s     = Validation (prediction) runtime\n",
      "Fitting simple weighted ensemble.\n",
      "\tEnsemble weights: {'DirectTabular': 0.12, 'RecursiveTabular': 0.01, 'SeasonalNaive': 0.27, 'TemporalFusionTransformer': 0.6}\n",
      "\t-9.2395       = Validation score (-RMSE)\n",
      "\t2.35    s     = Training runtime\n",
      "\t9.89    s     = Validation (prediction) runtime\n",
      "Training complete. Models trained: ['Naive', 'SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'TemporalFusionTransformer', 'WeightedEnsemble']\n",
      "Total runtime: 253.99 s\n",
      "Best model: WeightedEnsemble\n",
      "Best model score: -9.2395\n"
     ]
    }
   ],
   "source": [
    "predictor = TimeSeriesPredictor(\n",
    "    prediction_length=prediction_length,\n",
    "    path=\"autogluon-m4-hourly\",\n",
    "    target=\"target\",\n",
    "    eval_metric=eRMSE,\n",
    "    freq=\"15min\"\n",
    ")\n",
    "\n",
    "# TODO Increase Time Limit For Final Version\n",
    "predictor = predictor.fit(\n",
    "    train,\n",
    "    presets=\"medium_quality\",\n",
    "    time_limit=dev_runtime,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-12T09:02:26.903388300Z",
     "start_time": "2024-09-12T08:58:07.129322700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Full Search"
   ],
   "metadata": {
    "collapsed": false,
    "id": "_qKvSSnLjfLF"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Beginning AutoGluon training... Time limit = 10500s\n",
      "AutoGluon will save models to 'AutogluonModels\\ag-20240912_073936'\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.9.13\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22631\n",
      "CPU Count:          12\n",
      "GPU Count:          0\n",
      "Memory Avail:       0.71 GB / 15.34 GB (4.6%)\n",
      "Disk Space Avail:   80.50 GB / 474.72 GB (17.0%)\n",
      "===================================================\n",
      "Setting presets to: best_quality\n",
      "\n",
      "Fitting with arguments:\n",
      "{'enable_ensemble': True,\n",
      " 'eval_metric': WQL,\n",
      " 'hyperparameters': {'ADIDAModel': {},\n",
      "                     'AutoETSModel': {},\n",
      "                     'Chronos': {'batch_size': 64,\n",
      "                                 'device': 'cpu',\n",
      "                                 'model_path': 'tiny',\n",
      "                                 'optimization_strategy': 'openvino'},\n",
      "                     'CrostonSBAModel': {},\n",
      "                     'DLinearModel': {},\n",
      "                     'DeepARModel': {},\n",
      "                     'ETSModel': {},\n",
      "                     'IMAPAModel': {},\n",
      "                     'NaiveModel': {},\n",
      "                     'PatchTSTModel': {},\n",
      "                     'RecursiveTabularModel': {},\n",
      "                     'SeasonalNaiveModel': {},\n",
      "                     'SimpleFeedForwardModel': {},\n",
      "                     'TemporalFusionTransformerModel': {},\n",
      "                     'TiDEModel': {},\n",
      "                     'WaveNetModel': {}},\n",
      " 'known_covariates_names': [],\n",
      " 'num_val_windows': 2,\n",
      " 'prediction_length': 48,\n",
      " 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
      " 'random_seed': 123,\n",
      " 'refit_every_n_windows': 1,\n",
      " 'refit_full': False,\n",
      " 'skip_model_selection': False,\n",
      " 'target': 'target',\n",
      " 'time_limit': 10500,\n",
      " 'verbosity': 2}\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Frequency of train_data is not provided and cannot be inferred. Please set the expected data frequency when creating the predictor with `TimeSeriesPredictor(freq=...)` or ensure that the data has a regular time index with `train_data.convert_frequency(freq=...)`",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 4\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Model Exploration Exploration\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;66;03m# TODO Custom Config that compares all Models from Model Zoo\u001B[39;00m\n\u001B[0;32m      3\u001B[0m predictor \u001B[38;5;241m=\u001B[39m TimeSeriesPredictor(prediction_length\u001B[38;5;241m=\u001B[39mprediction_length)\n\u001B[1;32m----> 4\u001B[0m predictor \u001B[38;5;241m=\u001B[39m \u001B[43mpredictor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhyperparameters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m{\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mChronos\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\n\u001B[0;32m      8\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmodel_path\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtiny\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      9\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mbatch_size\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m64\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     10\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdevice\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcpu\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     11\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43moptimization_strategy\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mopenvino\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     12\u001B[0m \u001B[43m        \u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     13\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mNaiveModel\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     14\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mSeasonalNaiveModel\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     15\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m#\"AverageModel\": {},\u001B[39;49;00m\n\u001B[0;32m     16\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m#\"SeasonalAverageModel\": {},\u001B[39;49;00m\n\u001B[0;32m     17\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m#\"ZeroModel\": {},\u001B[39;49;00m\n\u001B[0;32m     18\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mETSModel\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     19\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m#\"AutoARIMAModel\": {\"n_jobs\": -1},\u001B[39;49;00m\n\u001B[0;32m     20\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mAutoETSModel\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     21\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m#\"AutoCESModel\": {},\u001B[39;49;00m\n\u001B[0;32m     22\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m#\"ThetaModel\": {},\u001B[39;49;00m\n\u001B[0;32m     23\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mADIDAModel\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     24\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m#\"CrostonClassicModel\": {},\u001B[39;49;00m\n\u001B[0;32m     25\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m#\"CrostonOptimizedModel\": {},\u001B[39;49;00m\n\u001B[0;32m     26\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mCrostonSBAModel\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     27\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mIMAPAModel\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     28\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m#\"NPTSModel\": {},\u001B[39;49;00m\n\u001B[0;32m     29\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mDeepARModel\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     30\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mDLinearModel\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     31\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mPatchTSTModel\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     32\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mSimpleFeedForwardModel\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     33\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mTemporalFusionTransformerModel\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     34\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mTiDEModel\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     35\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mWaveNetModel\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     36\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m#\"DirectTabularModel\": {},\u001B[39;49;00m\n\u001B[0;32m     37\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mRecursiveTabularModel\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     38\u001B[0m \u001B[43m    \u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     39\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m#verbosity=0,\u001B[39;49;00m\n\u001B[0;32m     40\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpresets\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mbest_quality\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     41\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtime_limit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlong_runtime\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     42\u001B[0m \u001B[43m)\u001B[49m\n\u001B[0;32m     43\u001B[0m \u001B[38;5;66;03m# TODO Investigate Leaderboard\u001B[39;00m\n\u001B[0;32m     44\u001B[0m \u001B[38;5;28mprint\u001B[39m(predictor\u001B[38;5;241m.\u001B[39mevaluate(val))\n",
      "File \u001B[1;32m~\\Documents\\UNI\\Projects\\24cast\\venv\\lib\\site-packages\\autogluon\\core\\utils\\decorators.py:31\u001B[0m, in \u001B[0;36munpack.<locals>._unpack_inner.<locals>._call\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     28\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(f)\n\u001B[0;32m     29\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_call\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m     30\u001B[0m     gargs, gkwargs \u001B[38;5;241m=\u001B[39m g(\u001B[38;5;241m*\u001B[39mother_args, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m---> 31\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m f(\u001B[38;5;241m*\u001B[39mgargs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mgkwargs)\n",
      "File \u001B[1;32m~\\Documents\\UNI\\Projects\\24cast\\venv\\lib\\site-packages\\autogluon\\timeseries\\predictor.py:701\u001B[0m, in \u001B[0;36mTimeSeriesPredictor.fit\u001B[1;34m(self, train_data, tuning_data, time_limit, presets, hyperparameters, hyperparameter_tune_kwargs, excluded_model_types, num_val_windows, val_step_size, refit_every_n_windows, refit_full, enable_ensemble, skip_model_selection, random_seed, verbosity)\u001B[0m\n\u001B[0;32m    698\u001B[0m logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mFitting with arguments:\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    699\u001B[0m logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpprint\u001B[38;5;241m.\u001B[39mpformat({k:\u001B[38;5;250m \u001B[39mv\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mfor\u001B[39;00m\u001B[38;5;250m \u001B[39mk,\u001B[38;5;250m \u001B[39mv\u001B[38;5;250m \u001B[39m\u001B[38;5;129;01min\u001B[39;00m\u001B[38;5;250m \u001B[39mfit_args\u001B[38;5;241m.\u001B[39mitems()\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mif\u001B[39;00m\u001B[38;5;250m \u001B[39mv\u001B[38;5;250m \u001B[39m\u001B[38;5;129;01mis\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;129;01mnot\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m})\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 701\u001B[0m train_data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_check_and_prepare_data_frame\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_data\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtrain_data\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    702\u001B[0m logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mProvided train_data has \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_dataset_stats(train_data)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    704\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m val_step_size \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32m~\\Documents\\UNI\\Projects\\24cast\\venv\\lib\\site-packages\\autogluon\\timeseries\\predictor.py:305\u001B[0m, in \u001B[0;36mTimeSeriesPredictor._check_and_prepare_data_frame\u001B[1;34m(self, data, name)\u001B[0m\n\u001B[0;32m    303\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfreq \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    304\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m df\u001B[38;5;241m.\u001B[39mfreq \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 305\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    306\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFrequency of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m is not provided and cannot be inferred. Please set the expected data \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    307\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfrequency when creating the predictor with `TimeSeriesPredictor(freq=...)` or ensure that \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    308\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mthe data has a regular time index with `\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.convert_frequency(freq=...)`\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    309\u001B[0m         )\n\u001B[0;32m    310\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    311\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfreq \u001B[38;5;241m=\u001B[39m df\u001B[38;5;241m.\u001B[39mfreq\n",
      "\u001B[1;31mValueError\u001B[0m: Frequency of train_data is not provided and cannot be inferred. Please set the expected data frequency when creating the predictor with `TimeSeriesPredictor(freq=...)` or ensure that the data has a regular time index with `train_data.convert_frequency(freq=...)`"
     ]
    }
   ],
   "source": [
    "# Model Exploration Exploration\n",
    "# TODO Custom Config that compares all Models from Model Zoo\n",
    "predictor = TimeSeriesPredictor(prediction_length=prediction_length, eval_metric=eRMSE)\n",
    "predictor = predictor.fit(\n",
    "    train,\n",
    "    hyperparameters={\n",
    "        \"Chronos\": {\n",
    "            \"model_path\": \"tiny\",\n",
    "            \"batch_size\": 64,\n",
    "            \"device\": \"cpu\",\n",
    "            \"optimization_strategy\": \"openvino\",\n",
    "        },\n",
    "        \"NaiveModel\": {},\n",
    "        \"SeasonalNaiveModel\": {},\n",
    "        \"AverageModel\": {},\n",
    "        \"SeasonalAverageModel\": {},\n",
    "        \"ZeroModel\": {},\n",
    "        \"ETSModel\": {},\n",
    "        \"AutoARIMAModel\": {\"n_jobs\": -1},\n",
    "        \"AutoETSModel\": {},\n",
    "        \"AutoCESModel\": {},\n",
    "        \"ThetaModel\": {},\n",
    "        \"ADIDAModel\": {},\n",
    "        #\"CrostonClassicModel\": {},\n",
    "        #\"CrostonOptimizedModel\": {},\n",
    "        \"CrostonSBAModel\": {},\n",
    "        \"IMAPAModel\": {},\n",
    "        \"NPTSModel\": {},\n",
    "        \"DeepARModel\": {},\n",
    "        \"DLinearModel\": {},\n",
    "        \"PatchTSTModel\": {},\n",
    "        \"SimpleFeedForwardModel\": {},\n",
    "        \"TemporalFusionTransformerModel\": {},\n",
    "        \"TiDEModel\": {},\n",
    "        \"WaveNetModel\": {},\n",
    "        \"DirectTabularModel\": {},\n",
    "        \"RecursiveTabularModel\": {},\n",
    "    },\n",
    "    #verbosity=0,\n",
    "    presets=\"best_quality\",\n",
    "    time_limit=long_runtime,\n",
    ")\n",
    "# TODO Investigate Leaderboard\n",
    "print(predictor.evaluate(val))\n",
    "predictor.leaderboard()"
   ],
   "metadata": {
    "id": "TodlaUsajfLF",
    "ExecuteTime": {
     "end_time": "2024-09-12T07:39:40.286565900Z",
     "start_time": "2024-09-12T07:39:36.188103300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO Tune best found Config"
   ],
   "metadata": {
    "id": "ekSFMpJIjfLG"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Chronos"
   ],
   "metadata": {
    "collapsed": false,
    "id": "rfzDZQvQjfLG"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# TODO Test out Tiny Chronos compare to Large Chronos -> GPU and delay Worth it\n",
    "predictor = TimeSeriesPredictor(prediction_length=prediction_length, freq=\"15min\")\n",
    "predictor = predictor.fit(\n",
    "    train,\n",
    "    hyperparameters={\n",
    "        \"Chronos\": {\n",
    "            \"model_path\": \"tiny\",\n",
    "            \"batch_size\": 64,\n",
    "            \"device\": \"cpu\",\n",
    "            \"optimization_strategy\": \"openvino\",\n",
    "        }\n",
    "    },\n",
    "    skip_model_selection=True,\n",
    "    verbosity=0,\n",
    ")\n",
    "\n",
    "predictions = predictor.predict(train)\n",
    "predictor.plot(\n",
    "    data=pd.concat([train, val]), \n",
    "    predictions=predictions, \n",
    "    max_history_length=512-48,\n",
    ");"
   ],
   "metadata": {
    "id": "0huMUVTVKtzy",
    "ExecuteTime": {
     "end_time": "2024-09-11T16:01:40.763978700Z",
     "start_time": "2024-09-11T16:01:37.536402400Z"
    }
   },
   "execution_count": 73,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model Chronos[tiny] failed to predict with the following exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jimmy\\Documents\\UNI\\Projects\\24cast\\venv\\lib\\site-packages\\autogluon\\timeseries\\models\\chronos\\pipeline.py\", line 532, in from_pretrained\n",
      "    from optimum.intel import OVModelForSeq2SeqLM\n",
      "ModuleNotFoundError: No module named 'optimum.intel'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jimmy\\Documents\\UNI\\Projects\\24cast\\venv\\lib\\site-packages\\autogluon\\timeseries\\trainer\\abstract_trainer.py\", line 1183, in get_model_pred_dict\n",
      "    model_pred_dict[model_name] = self._predict_model(\n",
      "  File \"C:\\Users\\Jimmy\\Documents\\UNI\\Projects\\24cast\\venv\\lib\\site-packages\\autogluon\\timeseries\\trainer\\abstract_trainer.py\", line 1110, in _predict_model\n",
      "    return model.predict(data, known_covariates=known_covariates)\n",
      "  File \"C:\\Users\\Jimmy\\Documents\\UNI\\Projects\\24cast\\venv\\lib\\site-packages\\autogluon\\timeseries\\models\\abstract\\abstract_timeseries_model.py\", line 304, in predict\n",
      "    predictions = self._predict(data=data, known_covariates=known_covariates, **kwargs)\n",
      "  File \"C:\\Users\\Jimmy\\Documents\\UNI\\Projects\\24cast\\venv\\lib\\site-packages\\autogluon\\timeseries\\models\\chronos\\model.py\", line 303, in _predict\n",
      "    self.load_model_pipeline(context_length=context_length)\n",
      "  File \"C:\\Users\\Jimmy\\Documents\\UNI\\Projects\\24cast\\venv\\lib\\site-packages\\autogluon\\timeseries\\models\\chronos\\model.py\", line 235, in load_model_pipeline\n",
      "    pipeline = OptimizedChronosPipeline.from_pretrained(\n",
      "  File \"C:\\Users\\Jimmy\\Documents\\UNI\\Projects\\24cast\\venv\\lib\\site-packages\\autogluon\\timeseries\\models\\chronos\\pipeline.py\", line 534, in from_pretrained\n",
      "    raise ImportError(\n",
      "ImportError: Huggingface Optimum library must be installed with OpenVINO for using the `openvino` strategy\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Following models failed to predict: ['Chronos[tiny]']",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[73], line 17\u001B[0m\n\u001B[0;32m      2\u001B[0m predictor \u001B[38;5;241m=\u001B[39m TimeSeriesPredictor(prediction_length\u001B[38;5;241m=\u001B[39mprediction_length, freq\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m15min\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m      3\u001B[0m predictor \u001B[38;5;241m=\u001B[39m predictor\u001B[38;5;241m.\u001B[39mfit(\n\u001B[0;32m      4\u001B[0m     train,\n\u001B[0;32m      5\u001B[0m     hyperparameters\u001B[38;5;241m=\u001B[39m{\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     14\u001B[0m     verbosity\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m,\n\u001B[0;32m     15\u001B[0m )\n\u001B[1;32m---> 17\u001B[0m predictions \u001B[38;5;241m=\u001B[39m \u001B[43mpredictor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mval\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     18\u001B[0m predictor\u001B[38;5;241m.\u001B[39mplot(\n\u001B[0;32m     19\u001B[0m     data\u001B[38;5;241m=\u001B[39mpd\u001B[38;5;241m.\u001B[39mconcat([train, val]), \n\u001B[0;32m     20\u001B[0m     predictions\u001B[38;5;241m=\u001B[39mpredictions, \n\u001B[0;32m     21\u001B[0m     max_history_length\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m512\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m48\u001B[39m,\n\u001B[0;32m     22\u001B[0m );\n",
      "File \u001B[1;32m~\\Documents\\UNI\\Projects\\24cast\\venv\\lib\\site-packages\\autogluon\\timeseries\\predictor.py:845\u001B[0m, in \u001B[0;36mTimeSeriesPredictor.predict\u001B[1;34m(self, data, known_covariates, model, use_cache, random_seed)\u001B[0m\n\u001B[0;32m    843\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m known_covariates \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    844\u001B[0m     known_covariates \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_to_data_frame(known_covariates)\n\u001B[1;32m--> 845\u001B[0m predictions \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_learner\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    846\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    847\u001B[0m \u001B[43m    \u001B[49m\u001B[43mknown_covariates\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mknown_covariates\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    848\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    849\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    850\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrandom_seed\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrandom_seed\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    851\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    852\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m predictions\u001B[38;5;241m.\u001B[39mreindex(original_item_id_order, level\u001B[38;5;241m=\u001B[39mITEMID)\n",
      "File \u001B[1;32m~\\Documents\\UNI\\Projects\\24cast\\venv\\lib\\site-packages\\autogluon\\timeseries\\learner.py:185\u001B[0m, in \u001B[0;36mTimeSeriesLearner.predict\u001B[1;34m(self, data, known_covariates, model, use_cache, random_seed, **kwargs)\u001B[0m\n\u001B[0;32m    183\u001B[0m known_covariates \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfeature_generator\u001B[38;5;241m.\u001B[39mtransform_future_known_covariates(known_covariates)\n\u001B[0;32m    184\u001B[0m known_covariates \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_align_covariates_with_forecast_index(known_covariates\u001B[38;5;241m=\u001B[39mknown_covariates, data\u001B[38;5;241m=\u001B[39mdata)\n\u001B[1;32m--> 185\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mload_trainer()\u001B[38;5;241m.\u001B[39mpredict(\n\u001B[0;32m    186\u001B[0m     data\u001B[38;5;241m=\u001B[39mdata,\n\u001B[0;32m    187\u001B[0m     known_covariates\u001B[38;5;241m=\u001B[39mknown_covariates,\n\u001B[0;32m    188\u001B[0m     model\u001B[38;5;241m=\u001B[39mmodel,\n\u001B[0;32m    189\u001B[0m     use_cache\u001B[38;5;241m=\u001B[39muse_cache,\n\u001B[0;32m    190\u001B[0m     random_seed\u001B[38;5;241m=\u001B[39mrandom_seed,\n\u001B[0;32m    191\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m    192\u001B[0m )\n",
      "File \u001B[1;32m~\\Documents\\UNI\\Projects\\24cast\\venv\\lib\\site-packages\\autogluon\\timeseries\\trainer\\abstract_trainer.py:896\u001B[0m, in \u001B[0;36mAbstractTimeSeriesTrainer.predict\u001B[1;34m(self, data, known_covariates, model, use_cache, random_seed, **kwargs)\u001B[0m\n\u001B[0;32m    886\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpredict\u001B[39m(\n\u001B[0;32m    887\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    888\u001B[0m     data: TimeSeriesDataFrame,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    893\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m    894\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m TimeSeriesDataFrame:\n\u001B[0;32m    895\u001B[0m     model_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_model_for_prediction(model)\n\u001B[1;32m--> 896\u001B[0m     model_pred_dict \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_model_pred_dict\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    897\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel_names\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    898\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    899\u001B[0m \u001B[43m        \u001B[49m\u001B[43mknown_covariates\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mknown_covariates\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    900\u001B[0m \u001B[43m        \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    901\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrandom_seed\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrandom_seed\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    902\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    903\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m model_pred_dict[model_name]\n",
      "File \u001B[1;32m~\\Documents\\UNI\\Projects\\24cast\\venv\\lib\\site-packages\\autogluon\\timeseries\\trainer\\abstract_trainer.py:1198\u001B[0m, in \u001B[0;36mAbstractTimeSeriesTrainer.get_model_pred_dict\u001B[1;34m(self, model_names, data, known_covariates, record_pred_time, raise_exception_if_failed, use_cache, random_seed)\u001B[0m\n\u001B[0;32m   1195\u001B[0m             pred_time_dict_marginal[model_name] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1197\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(failed_models) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m raise_exception_if_failed:\n\u001B[1;32m-> 1198\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFollowing models failed to predict: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfailed_models\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   1199\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcache_predictions \u001B[38;5;129;01mand\u001B[39;00m use_cache:\n\u001B[0;32m   1200\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_save_cached_pred_dicts(\n\u001B[0;32m   1201\u001B[0m         dataset_hash, model_pred_dict\u001B[38;5;241m=\u001B[39mmodel_pred_dict, pred_time_dict\u001B[38;5;241m=\u001B[39mpred_time_dict_marginal\n\u001B[0;32m   1202\u001B[0m     )\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Following models failed to predict: ['Chronos[tiny]']"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO Is Finetuned Tiny much better than untuned Tiny\n",
    "# TODO Speed up Chronos\n",
    "# TODO How compare to classical AG"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
